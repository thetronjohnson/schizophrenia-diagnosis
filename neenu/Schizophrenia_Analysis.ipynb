{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Schizophrenia Analysis",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "'''Reading Data'''"
      ],
      "metadata": {
        "id": "LOfY4vk6SS7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mne\n",
        "from glob import glob\n",
        "import os\n",
        "import mne\n",
        "import numpy as np\n",
        "import pandas\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "CVA1mITP5SMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07bcc140-0fce-47f4-bd9f-b60344132323"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mne\n",
            "  Downloading mne-0.24.1-py3-none-any.whl (7.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4 MB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.19.5)\n",
            "Installing collected packages: mne\n",
            "Successfully installed mne-0.24.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allfile_path=glob('dataset/*.edf')\n",
        "allfile_path[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xn8OkPKr_OpB",
        "outputId": "2a20f8ae-b318-4cd6-c974-a27b6c68192a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'dataset/s05.edf'"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "healthy_path=[i for i in allfile_path if 'h' in i.split('/')[1]]\n",
        "patient_path=[i for i in allfile_path if 's' in i.split('/')[1]]"
      ],
      "metadata": {
        "id": "cMeAKMdV__zD"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_data(file_path):\n",
        "  data=mne.io.read_raw_edf(file_path, preload=True) #read data from file path\n",
        "  data.set_eeg_reference() #by default takes average of all channels\n",
        "  data.filter(l_freq=0.5,h_freq=45) # to be changed with bandpass filter?\n",
        "  #segmentation\n",
        "  epochs=mne.make_fixed_length_epochs(data,duration=5,overlap=1) #overlapping segments\n",
        "  array=epochs.get_data() #converts mne epoch object to numpy array\n",
        "  return(array)"
      ],
      "metadata": {
        "id": "WHTRVMj1CCP4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data=read_data(healthy_path[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49RN9V6zDV3_",
        "outputId": "945b0dd3-dc4c-4bc6-8b27-bd3f6a529880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting EDF parameters from /content/dataset/h10.edf...\n",
            "EDF file detected\n",
            "Setting channel info structure...\n",
            "Creating raw.info structure...\n",
            "Reading 0 ... 278749  =      0.000 ...  1114.996 secs...\n",
            "EEG channel type selected for re-referencing\n",
            "Applying average reference.\n",
            "Applying a custom ('EEG',) reference.\n",
            "Filtering raw data in 1 contiguous segment\n",
            "Setting up band-pass filter from 0.5 - 45 Hz\n",
            "\n",
            "FIR filter parameters\n",
            "---------------------\n",
            "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
            "- Windowed time-domain design (firwin) method\n",
            "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
            "- Lower passband edge: 0.50\n",
            "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 0.25 Hz)\n",
            "- Upper passband edge: 45.00 Hz\n",
            "- Upper transition bandwidth: 11.25 Hz (-6 dB cutoff frequency: 50.62 Hz)\n",
            "- Filter length: 1651 samples (6.604 sec)\n",
            "\n",
            "Not setting metadata\n",
            "Not setting metadata\n",
            "278 matching events found\n",
            "No baseline correction applied\n",
            "0 projection items activated\n",
            "Loading data for 278 events and 1250 original time points ...\n",
            "0 bad epochs dropped\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_data.shape # dimension of data => no.of epochs, channels , length of signal\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSNBtqF4Dum0",
        "outputId": "77837bc6-1c1f-4933-f564-f9ec1212c9c2"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(278, 19, 1250)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture \n",
        "#capture is used to prevent the data jargon from printing\n",
        "healthy_epochs_array=[read_data(i) for i in healthy_path]\n",
        "patient_epochs_array=[read_data(i) for i in patient_path]"
      ],
      "metadata": {
        "id": "mj-D6TgTD6x2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating labels 0 for healthy and 1 for patient\n",
        "healthy_epoch_labels=[len(i)*[0] for i in healthy_epochs_array]\n",
        "patient_epoch_labels=[len(i)*[1] for i in patient_epochs_array]"
      ],
      "metadata": {
        "id": "8wXIb2gWEodd"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_list=healthy_epochs_array+patient_epochs_array\n",
        "label_list=healthy_epoch_labels+patient_epoch_labels"
      ],
      "metadata": {
        "id": "0FWYq_FJEZQE"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#splitting \n",
        "group_list=[[i]*len(j) for i,j in enumerate(data_list)] #list of 0 for element 1 list of 1 for next etc multiplied bt length\n",
        "group_list"
      ],
      "metadata": {
        "id": "t-g-FafoGmaF"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_array=np.vstack(data_list) #stack arrays vertically\n",
        "label_array=np.hstack(label_list)\n",
        "group_array=np.hstack(group_list)\n",
        "\n",
        "#7201 epochs of length 1250\n",
        "print(data_array.shape)"
      ],
      "metadata": {
        "id": "bxEar-fVRpX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57c4f44-d169-4b1c-bae3-5e08e89d88a1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7201, 19, 1250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Feature Extaction'''"
      ],
      "metadata": {
        "id": "9nMX7xmFSGVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "def mean(x):\n",
        "  return(np.mean(x,axis=-1))\n",
        "def std(x):\n",
        "  return(np.std(x,axis=-1)) #standard deviation\n",
        "def ptp(x):\n",
        "  return(np.ptp(x,axis=-1)) # peak to peak value\n",
        "def var(x):\n",
        "  return(np.var(x,axis=-1)) #variance\n",
        "def minim(x):\n",
        "  return(np.min(x,axis=-1))\n",
        "def maxim(x):\n",
        "  return(np.max(x,axis=-1))\n",
        "def argminim(x):\n",
        "  return(np.argmin(x,axis=-1))\n",
        "def argmaxim(x):\n",
        "  return(np.argmax(x,axis=-1))\n",
        "def rms(x):\n",
        "  return(np.sqrt(np.mean(x**2,axis=-1))) #root mean square\n",
        "def abs_diff_signal(x):\n",
        "  return(np.sum(np.abs(np.diff(x,axis=-1)),axis=-1))\n",
        "\n",
        "def skewness(x):\n",
        "  return(stats.skew(x,axis=-1)) #to measure symmetry of dataset\n",
        "def kurtosis(x):\n",
        "  return(stats.kurtosis(x,axis=-1)) # measure of tailedness=> how heavy dataset's tails are compared to normal distribution\n",
        "\n",
        "def concatenate_features(x):\n",
        "  return(np.concatenate((mean(x),std(x),ptp(x),var(x),minim(x),maxim(x),argminim(x),argmaxim(x),rms(x),abs_diff_signal(x),skewness(x),kurtosis(x)),axis=-1))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kh4mtfL0IVbH"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features=[]\n",
        "for d in data_array:\n",
        "  features.append(concatenate_features(d))"
      ],
      "metadata": {
        "id": "wW9ZsUcrMFyf"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abs_diff_signal(d).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBnNTS2bOC2V",
        "outputId": "f82d175d-d837-4243-e9ec-7f6ecffdf981"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19,)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features_array=np.array(features)\n",
        "features_array.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8Lsu_j0Q8km",
        "outputId": "05d5d3d8-6001-4ad7-cdb7-f34b435b6070"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7201, 228)"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#we have 228/19=12 features for classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GroupKFold,GridSearchCV\n"
      ],
      "metadata": {
        "id": "xM32majrRLVP"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression()\n",
        "gkf=GroupKFold(5)\n",
        "pipe=Pipeline([('scalar',StandardScaler()),('clf',clf)])\n",
        "param_grid={'clf__C':[0.1,0.5,0.7,1,3,5,7]}\n",
        "gscv=GridSearchCV(pipe,param_grid,cv=gkf,n_jobs=12)\n",
        "gscv.fit(features_array,label_array,groups=group_array)\n"
      ],
      "metadata": {
        "id": "gbrmXCdJR-u_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b2f3ee4-292d-4f50-8737-713f88bfb2c8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=GroupKFold(n_splits=5),\n",
              "             estimator=Pipeline(steps=[('scalar', StandardScaler()),\n",
              "                                       ('clf', LogisticRegression())]),\n",
              "             n_jobs=12, param_grid={'clf__C': [0.1, 0.5, 0.7, 1, 3, 5, 7]})"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gscv.best_score_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BfRFaX_W6pa",
        "outputId": "c34eec7e-a3ad-4243-ef04-f5c28bf2d008"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6749861872931688"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Convolution'''"
      ],
      "metadata": {
        "id": "mL9aVUnLSMKF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}